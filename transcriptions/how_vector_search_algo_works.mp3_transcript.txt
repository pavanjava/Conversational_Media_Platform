 What makes the internet so addictive lately? Have you ever wondered how platforms like YouTube or TikTok knows exactly what videos to show you so that you will be most likely to watch? Or how online stores or ads knows exactly what products to show you so that you will be most likely to buy? All this is due to something called vector search. Imagine you just watched a video about rocket science. A simple keyword based search would only be able to recommend you other videos with the words rocket or science in it. But a vector search engine works in a much more sophisticated way. It can analyze the actual context and meaning of texts like the title, the transcript, or the description of the video, as well as user interactions such as likes, views, or watch time, and search them using high dimensional vectors. So the YouTube algorithm takes the vectors from this rocket science video and compares them against millions of other vectors from other videos in a fraction of a second. The ones with the closest matching vectors means that they cover similar topics but potentially from different angles. So they get resurfaced as a recommendation for you as you're scrolling through your timeline. Quadrant is a vector search engine that uses advanced search algorithms to go through high dimensional vector representations of any type of data. But what is exactly happening behind the scenes? Each piece of data inserted into quadrant is represented as a vector, say a 1536 dimensional vector collection of numbers like 1, 4, 3.2, minus 0.8, etc. Your query is also converted into a vector representation. Quadrant then calculates how similar the query vector is to every data vector, surfacing the closest matches in the entire dataset. Now imagine this playing out across millions or even billions of data points globally distributed. That is the crazy scale that Quadrant operates at and yet it manages to do so with incredible efficiency and using minimal compute resources. Quadrant is open source and free and can be readily modified and deployed in any environment of your choice. From personal projects on a Raspberry Pi to powering search on major corporations, even the biggest global companies can use Quadrant at the same level of complexity as a hobbyist from their home office. Combining Quadrant with large language models can give you more accurate and in-depth results than just using the LLM by itself. This creates powerful systems and we call it Retrival Augmented Generation or RAG. The Retrival process boosts the performance of AI models like chatbots, ensuring that generate high quality outputs while minimizing the resource usage and significantly reducing the operational costs. There's a lot more I can go into this topic so please if you want to keep going check out some other videos in this channel like Advanced Retrival Strategies or Semantic Cache. Also we have a growing discord community of vector search experts so if you'd like to join that to share ideas, projects and contribute to the future of vector search with us check out the link in the description.